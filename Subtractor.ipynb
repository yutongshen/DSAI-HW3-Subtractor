{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB      = 0\n",
    "SUB_ADD  = 1\n",
    "MULTIPLY = 2\n",
    "\n",
    "GEN_TYPE = SUB_ADD\n",
    "\n",
    "TRAINING_SIZE = 80000\n",
    "DIGITS = 3\n",
    "ANS_DIGITS = {\n",
    "    SUB: DIGITS + 1,\n",
    "    SUB_ADD: DIGITS + 1,\n",
    "    MULTIPLY: 2 * DIGITS\n",
    "}.get(GEN_TYPE, DIGITS + 1)\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = {\n",
    "    SUB: '0123456789- ',\n",
    "    SUB_ADD: '0123456789+- ',\n",
    "    MULTIPLY: '0123456789* '\n",
    "}.get(GEN_TYPE, '0123456789+-* ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 80000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "operator = {\n",
    "    SUB: ['-'],\n",
    "    SUB_ADD: ['-', '+'],\n",
    "    MULTIPLY: ['*']\n",
    "}\n",
    "ans_switcher = {\n",
    "    '+': lambda a, b: a + b,\n",
    "    '-': lambda a, b: a - b,\n",
    "    '*': lambda a, b: a * b\n",
    "}\n",
    "ops = operator.get(GEN_TYPE, [None])\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: random.choice(range(10 ** random.choice(range(1, DIGITS + 1))))\n",
    "    g = lambda: random.choice(ops)\n",
    "    a, b, op = f(), f(), g()\n",
    "    if op == '-':\n",
    "        a, b = sorted((a, b), reverse=True)\n",
    "    key = tuple((a, b, op))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "#     query = '{}{}{}'.format(a, op, b).ljust(MAXLEN)\n",
    "    query = str(a).rjust(DIGITS) + op + str(b).rjust(DIGITS)\n",
    "    ans_funct = ans_switcher.get(op, lambda a, b: float('NAN'))\n",
    "    ans = str(ans_funct(a, b)).rjust(ANS_DIGITS)\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736-  9 =  727\n",
      "  9+ 95 =  104\n",
      "590+ 54 =  644\n",
      " 79-  5 =   74\n",
      " 38-  1 =   37\n",
      " 82+  2 =   84\n",
      " 27+ 30 =   57\n",
      "  7-  7 =    0\n",
      " 63- 50 =   13\n",
      "579-  7 =  572\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(questions[i], '=', expected[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "- Size of training data:   64,000\n",
    "- Size of validation data: 16,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable:\n",
    "    def __init__(self, chars):\n",
    "        self.chars  = list(chars)\n",
    "        self.len    = len(chars)\n",
    "        self.encode = {}\n",
    "        for i, key in enumerate(self.chars):\n",
    "            self.encode[key] = np.zeros(self.len, np.float32)\n",
    "            self.encode[key][i] = 1.\n",
    "            \n",
    "    def encoder(self, C):\n",
    "        result = np.zeros((len(C), self.len))\n",
    "        for i, c in enumerate(C):\n",
    "            try:\n",
    "                result[i] = self.encode[c]\n",
    "            except:\n",
    "                pass\n",
    "        return result\n",
    "            \n",
    "    def decoder(self, x):\n",
    "        x = x.argmax(axis=-1)\n",
    "        return ''.join(self.chars[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CharacterTable(chars)\n",
    "\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), np.float32)\n",
    "y = np.zeros((len(expected), ANS_DIGITS, len(chars)), np.float32)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ct.encoder(sentence)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ct.encoder(sentence)\n",
    "\n",
    "train_x = x[:64000]\n",
    "train_y = y[:64000]\n",
    "\n",
    "validation_x = x[64000:80000]\n",
    "validation_y = y[64000:80000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "![model](img/seq2seq.png)\n",
    "\n",
    "- Using sequence to sequence model\n",
    "- Encoder: bi-directional LSTM\n",
    "- Decoder: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddnn_user02/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 7, 13)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 512), (None, 552960      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 512)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 512), (None, 2099200     reshape_1[0][0]                  \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[2][1]                     \n",
      "                                                                 lstm_2[2][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 13)           6669        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 13)           6669        lstm_2[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 13)           6669        lstm_2[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 13)           6669        lstm_2[3][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 52)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 4, 13)        0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4, 13)        0           reshape_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,678,836\n",
      "Trainable params: 2,678,836\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 64000 samples, validate on 16000 samples\n",
      "Epoch 1/100\n",
      "64000/64000 [==============================] - 10s 159us/step - loss: 1.6879 - acc: 0.3748 - val_loss: 1.5375 - val_acc: 0.3973\n",
      "Epoch 2/100\n",
      "64000/64000 [==============================] - 7s 105us/step - loss: 1.3517 - acc: 0.4758 - val_loss: 1.3638 - val_acc: 0.4675\n",
      "Epoch 3/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 1.1953 - acc: 0.5340 - val_loss: 1.2169 - val_acc: 0.5284\n",
      "Epoch 4/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 1.0278 - acc: 0.6055 - val_loss: 1.0182 - val_acc: 0.6099\n",
      "Epoch 5/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.8637 - acc: 0.6727 - val_loss: 0.8221 - val_acc: 0.6861\n",
      "Epoch 6/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.5998 - acc: 0.7816 - val_loss: 0.4866 - val_acc: 0.8350\n",
      "Epoch 7/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.3221 - acc: 0.9177 - val_loss: 0.2583 - val_acc: 0.9496\n",
      "Epoch 8/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 0.1725 - acc: 0.9727 - val_loss: 0.1686 - val_acc: 0.9681\n",
      "Epoch 9/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 0.0986 - acc: 0.9865 - val_loss: 0.0821 - val_acc: 0.9903\n",
      "Epoch 10/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 0.0658 - acc: 0.9900 - val_loss: 0.0974 - val_acc: 0.9776\n",
      "Epoch 11/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 0.0394 - acc: 0.9960 - val_loss: 0.0357 - val_acc: 0.9965\n",
      "Epoch 12/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.0198 - acc: 0.9994 - val_loss: 0.0265 - val_acc: 0.9971\n",
      "Epoch 13/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 0.0161 - acc: 0.9989 - val_loss: 0.0261 - val_acc: 0.9958\n",
      "Epoch 14/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.0443 - acc: 0.9886 - val_loss: 0.0426 - val_acc: 0.9887\n",
      "Epoch 15/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 0.0120 - acc: 0.9992 - val_loss: 0.0122 - val_acc: 0.9993\n",
      "Epoch 16/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 0.9993\n",
      "Epoch 17/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9995\n",
      "Epoch 18/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 0.9996\n",
      "Epoch 19/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9997\n",
      "Epoch 20/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9997\n",
      "Epoch 21/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9997\n",
      "Epoch 22/100\n",
      "64000/64000 [==============================] - 6s 98us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9997\n",
      "Epoch 23/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9997\n",
      "Epoch 24/100\n",
      "64000/64000 [==============================] - 7s 105us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9997\n",
      "Epoch 25/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9998\n",
      "Epoch 27/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9998\n",
      "Epoch 28/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 9.3872e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9997\n",
      "Epoch 29/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 8.3903e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9998\n",
      "Epoch 30/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 7.5261e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9998\n",
      "Epoch 31/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 6.7740e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9997\n",
      "Epoch 32/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 6.1113e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9998\n",
      "Epoch 33/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 5.5201e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9998\n",
      "Epoch 34/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 5.0014e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9997\n",
      "Epoch 35/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 4.5403e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9998\n",
      "Epoch 36/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 4.1226e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9998\n",
      "Epoch 37/100\n",
      "64000/64000 [==============================] - 7s 104us/step - loss: 3.7570e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9998\n",
      "Epoch 38/100\n",
      "64000/64000 [==============================] - 7s 104us/step - loss: 3.4227e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9998\n",
      "Epoch 39/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 3.1246e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9998\n",
      "Epoch 40/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 2.8606e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9997\n",
      "Epoch 41/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 2.6189e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9997\n",
      "Epoch 42/100\n",
      "64000/64000 [==============================] - 7s 104us/step - loss: 2.3916e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 0.9998\n",
      "Epoch 43/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 2.1909e-04 - acc: 1.0000 - val_loss: 8.5758e-04 - val_acc: 0.9998\n",
      "Epoch 44/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 2.0179e-04 - acc: 1.0000 - val_loss: 8.9678e-04 - val_acc: 0.9998\n",
      "Epoch 45/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 1.8475e-04 - acc: 1.0000 - val_loss: 8.5631e-04 - val_acc: 0.9998\n",
      "Epoch 46/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 1.6972e-04 - acc: 1.0000 - val_loss: 8.9097e-04 - val_acc: 0.9998\n",
      "Epoch 47/100\n",
      "64000/64000 [==============================] - 6s 98us/step - loss: 1.5627e-04 - acc: 1.0000 - val_loss: 8.2744e-04 - val_acc: 0.9998\n",
      "Epoch 48/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 1.4373e-04 - acc: 1.0000 - val_loss: 7.7837e-04 - val_acc: 0.9998\n",
      "Epoch 49/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 1.3227e-04 - acc: 1.0000 - val_loss: 7.2930e-04 - val_acc: 0.9998\n",
      "Epoch 50/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 1.2187e-04 - acc: 1.0000 - val_loss: 7.1634e-04 - val_acc: 0.9998\n",
      "Epoch 51/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 1.1257e-04 - acc: 1.0000 - val_loss: 6.9101e-04 - val_acc: 0.9998\n",
      "Epoch 52/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 1.0373e-04 - acc: 1.0000 - val_loss: 6.2596e-04 - val_acc: 0.9998\n",
      "Epoch 53/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 9.5786e-05 - acc: 1.0000 - val_loss: 6.8984e-04 - val_acc: 0.9998\n",
      "Epoch 54/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 8.8539e-05 - acc: 1.0000 - val_loss: 7.4690e-04 - val_acc: 0.9997\n",
      "Epoch 55/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 8.1882e-05 - acc: 1.0000 - val_loss: 5.8840e-04 - val_acc: 0.9998\n",
      "Epoch 56/100\n",
      "64000/64000 [==============================] - 6s 99us/step - loss: 7.5658e-05 - acc: 1.0000 - val_loss: 5.5852e-04 - val_acc: 0.9998\n",
      "Epoch 57/100\n",
      "64000/64000 [==============================] - 7s 104us/step - loss: 7.0058e-05 - acc: 1.0000 - val_loss: 6.3494e-04 - val_acc: 0.9998\n",
      "Epoch 58/100\n",
      "64000/64000 [==============================] - 7s 104us/step - loss: 6.4691e-05 - acc: 1.0000 - val_loss: 6.0999e-04 - val_acc: 0.9998\n",
      "Epoch 59/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 5.9872e-05 - acc: 1.0000 - val_loss: 5.4054e-04 - val_acc: 0.9998\n",
      "Epoch 60/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 5.5417e-05 - acc: 1.0000 - val_loss: 5.8385e-04 - val_acc: 0.9997\n",
      "Epoch 61/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 5.1354e-05 - acc: 1.0000 - val_loss: 5.5639e-04 - val_acc: 0.9998\n",
      "Epoch 62/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 4.7571e-05 - acc: 1.0000 - val_loss: 4.7734e-04 - val_acc: 0.9999\n",
      "Epoch 63/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 4.4142e-05 - acc: 1.0000 - val_loss: 4.9962e-04 - val_acc: 0.9998\n",
      "Epoch 64/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 4.0925e-05 - acc: 1.0000 - val_loss: 4.9708e-04 - val_acc: 0.9998\n",
      "Epoch 65/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 3.8045e-05 - acc: 1.0000 - val_loss: 4.7659e-04 - val_acc: 0.9998\n",
      "Epoch 66/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 3.5212e-05 - acc: 1.0000 - val_loss: 4.6216e-04 - val_acc: 0.9998\n",
      "Epoch 67/100\n",
      "64000/64000 [==============================] - 6s 102us/step - loss: 3.2706e-05 - acc: 1.0000 - val_loss: 4.2926e-04 - val_acc: 0.9998\n",
      "Epoch 68/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 3.0389e-05 - acc: 1.0000 - val_loss: 3.9845e-04 - val_acc: 0.9999\n",
      "Epoch 69/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 2.8219e-05 - acc: 1.0000 - val_loss: 3.9067e-04 - val_acc: 0.9998\n",
      "Epoch 70/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 2.6242e-05 - acc: 1.0000 - val_loss: 3.8886e-04 - val_acc: 0.9998\n",
      "Epoch 71/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 2.4398e-05 - acc: 1.0000 - val_loss: 4.3251e-04 - val_acc: 0.9998\n",
      "Epoch 72/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 2.2663e-05 - acc: 1.0000 - val_loss: 3.5850e-04 - val_acc: 0.9999\n",
      "Epoch 73/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 2.1069e-05 - acc: 1.0000 - val_loss: 4.2770e-04 - val_acc: 0.9998\n",
      "Epoch 74/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 1.9648e-05 - acc: 1.0000 - val_loss: 3.5328e-04 - val_acc: 0.9999\n",
      "Epoch 75/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 1.8283e-05 - acc: 1.0000 - val_loss: 3.9291e-04 - val_acc: 0.9998\n",
      "Epoch 76/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 1.6997e-05 - acc: 1.0000 - val_loss: 3.4542e-04 - val_acc: 0.9998\n",
      "Epoch 77/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 1.5823e-05 - acc: 1.0000 - val_loss: 3.6805e-04 - val_acc: 0.9998\n",
      "Epoch 78/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 1.4759e-05 - acc: 1.0000 - val_loss: 3.7950e-04 - val_acc: 0.9998\n",
      "Epoch 79/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 1.3767e-05 - acc: 1.0000 - val_loss: 3.4198e-04 - val_acc: 0.9999\n",
      "Epoch 80/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 1.2799e-05 - acc: 1.0000 - val_loss: 4.0550e-04 - val_acc: 0.9998\n",
      "Epoch 81/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 1.1951e-05 - acc: 1.0000 - val_loss: 4.3830e-04 - val_acc: 0.9998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "64000/64000 [==============================] - 7s 104us/step - loss: 1.1146e-05 - acc: 1.0000 - val_loss: 3.4140e-04 - val_acc: 0.9999\n",
      "Epoch 83/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 1.0378e-05 - acc: 1.0000 - val_loss: 3.6021e-04 - val_acc: 0.9998\n",
      "Epoch 84/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 9.6933e-06 - acc: 1.0000 - val_loss: 3.2435e-04 - val_acc: 0.9998\n",
      "Epoch 85/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 9.0426e-06 - acc: 1.0000 - val_loss: 3.4797e-04 - val_acc: 0.9999\n",
      "Epoch 86/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 8.4410e-06 - acc: 1.0000 - val_loss: 3.7091e-04 - val_acc: 0.9998\n",
      "Epoch 87/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 7.8817e-06 - acc: 1.0000 - val_loss: 3.7478e-04 - val_acc: 0.9999\n",
      "Epoch 88/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 7.3644e-06 - acc: 1.0000 - val_loss: 3.3259e-04 - val_acc: 0.9998\n",
      "Epoch 89/100\n",
      "64000/64000 [==============================] - 7s 104us/step - loss: 6.8752e-06 - acc: 1.0000 - val_loss: 2.9419e-04 - val_acc: 0.9999\n",
      "Epoch 90/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 6.4179e-06 - acc: 1.0000 - val_loss: 3.1387e-04 - val_acc: 0.9998\n",
      "Epoch 91/100\n",
      "64000/64000 [==============================] - 7s 103us/step - loss: 6.0039e-06 - acc: 1.0000 - val_loss: 3.1876e-04 - val_acc: 0.9998\n",
      "Epoch 92/100\n",
      "64000/64000 [==============================] - 7s 102us/step - loss: 5.6287e-06 - acc: 1.0000 - val_loss: 2.8103e-04 - val_acc: 0.9999\n",
      "Epoch 93/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 5.2431e-06 - acc: 1.0000 - val_loss: 3.3694e-04 - val_acc: 0.9998\n",
      "Epoch 94/100\n",
      "64000/64000 [==============================] - 6s 99us/step - loss: 4.9090e-06 - acc: 1.0000 - val_loss: 2.9761e-04 - val_acc: 0.9999\n",
      "Epoch 95/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 4.5911e-06 - acc: 1.0000 - val_loss: 2.5645e-04 - val_acc: 0.9999\n",
      "Epoch 96/100\n",
      "64000/64000 [==============================] - 6s 101us/step - loss: 4.2944e-06 - acc: 1.0000 - val_loss: 3.0865e-04 - val_acc: 0.9999\n",
      "Epoch 97/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 4.0175e-06 - acc: 1.0000 - val_loss: 3.3563e-04 - val_acc: 0.9999\n",
      "Epoch 98/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 3.7620e-06 - acc: 1.0000 - val_loss: 3.8113e-04 - val_acc: 0.9999\n",
      "Epoch 99/100\n",
      "64000/64000 [==============================] - 6s 102us/step - loss: 3.5220e-06 - acc: 1.0000 - val_loss: 2.9041e-04 - val_acc: 0.9999\n",
      "Epoch 100/100\n",
      "64000/64000 [==============================] - 6s 100us/step - loss: 3.2996e-06 - acc: 1.0000 - val_loss: 2.9259e-04 - val_acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1d701e4668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Lambda\n",
    "from keras.layers import Input, LSTM, TimeDistributed, Dropout, RepeatVector, Reshape, Bidirectional, Concatenate, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "EMBEDDING_SIZE = 256\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "encoder_inputs = Input(shape=(MAXLEN, len(chars)))\n",
    "# encoder_inputs = Input(shape=(MAXLEN,))\n",
    "# embedding = Embedding(len(chars), EMBEDDING_SIZE)(encoder_inputs)\n",
    "encoder = Bidirectional(LSTM(HIDDEN_SIZE, return_state=True))\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "states = [state_h, state_c]\n",
    "\n",
    "# decoder_inputs = RepeatVector(ANS_DIGITS)(encoder_outputs)\n",
    "# decoder_outputs = Bidirectional(LSTM(int(HIDDEN_SIZE / 2), return_sequences=True))(decoder_inputs)\n",
    "# decoder_outputs = TimeDistributed(Dense(len(chars), activation='softmax'))(decoder_outputs)\n",
    "\n",
    "# Set up the decoder, which will only process one timestep at a time.\n",
    "decoder_inputs = Reshape((1, HIDDEN_SIZE * 2))\n",
    "decoder_lstm = LSTM(HIDDEN_SIZE * 2, return_state=True)\n",
    "\n",
    "all_outputs = []\n",
    "inputs = decoder_inputs(encoder_outputs)\n",
    "\n",
    "first_decoder = True\n",
    "for _ in range(ANS_DIGITS):\n",
    "    # Run the decoder on one timestep\n",
    "    outputs, state_h, state_c = decoder_lstm(inputs,\n",
    "                                             initial_state=states)\n",
    "    \n",
    "    # Reinject the outputs as inputs for the next loop iteration\n",
    "    # as well as update the states\n",
    "    states = [state_h, state_c]\n",
    "#     inputs = decoder_inputs(outputs)\n",
    "    \n",
    "    # Store the current prediction (we will concatenate all predictions later)\n",
    "    outputs = Dense(len(chars), activation='softmax')(outputs)\n",
    "    all_outputs.append(outputs)\n",
    "    \n",
    "\n",
    "# Concatenate all predictions\n",
    "decoder_outputs = Concatenate()(all_outputs)\n",
    "decoder_outputs = Reshape((ANS_DIGITS, len(chars)))(decoder_outputs)\n",
    "decoder_outputs = Lambda(lambda x: x[:,::-1])(decoder_outputs)\n",
    "\n",
    "# Define and compile model as previously\n",
    "model = Model(encoder_inputs, decoder_outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = int(len(train_x) / 128 / 100) * 100\n",
    "\n",
    "if batch_size == 0:\n",
    "    batch_size = 100\n",
    "\n",
    "    \n",
    "model.fit(train_x, train_y, \n",
    "          batch_size=batch_size, epochs=100, \n",
    "          verbose=1, validation_data=[validation_x, validation_y])\n",
    "\n",
    "# model.fit(np.argmax(train_x, axis=2), train_y, \n",
    "#           batch_size=batch_size, epochs=100, \n",
    "#           verbose=1, validation_data=[np.argmax(validation_x, axis=2), validation_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error check\n",
      "7 / 80000\n",
      "\n",
      "Prediction     Ans\n",
      "-------------------\n",
      "341-236 =   05  105\n",
      "959+680 = 1539 1639\n",
      "936+155 = 1191 1091\n",
      "912+484 = 1496 1396\n",
      "915-807 =   08  108\n",
      "913+995 = 1808 1908\n",
      "603-502 =   01  101\n"
     ]
    }
   ],
   "source": [
    "print('Error check')\n",
    "pred = model.predict(x)\n",
    "err = []\n",
    "for i in range(len(x)):\n",
    "    if ct.decoder(pred[i]) != ct.decoder(y[i]):\n",
    "        err.append(i)\n",
    "print(len(err), '/', len(x))\n",
    "print()\n",
    "print('Prediction'.ljust(MAXLEN + ANS_DIGITS + 3),'Ans')\n",
    "print('-' * (MAXLEN + ANS_DIGITS * 2 + 4))\n",
    "for i in err:\n",
    "    print(ct.decoder(x[i]), '=', ct.decoder(pred[i]), ct.decoder(y[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100-5 =   98\n"
     ]
    }
   ],
   "source": [
    "q = '100-5'\n",
    "\n",
    "q_padding = q.ljust(MAXLEN)[:MAXLEN]\n",
    "test_x = ct.encoder(q_padding)\n",
    "pred_y = model.predict(test_x.reshape(-1, MAXLEN, len(chars)))\n",
    "print(q, '=', ct.decoder(pred_y[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
