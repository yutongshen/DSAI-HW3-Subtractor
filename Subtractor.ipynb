{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB      = 0\n",
    "SUB_ADD  = 1\n",
    "MULTIPLY = 2\n",
    "\n",
    "GEN_TYPE = SUB\n",
    "\n",
    "TRAINING_SIZE = 80000\n",
    "DIGITS = 3\n",
    "ANS_DIGITS = {\n",
    "    SUB: DIGITS + 1,\n",
    "    SUB_ADD: DIGITS + 1,\n",
    "    MULTIPLY: 2 * DIGITS\n",
    "}.get(GEN_TYPE, DIGITS + 1)\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = {\n",
    "    SUB: '0123456789- ',\n",
    "    SUB_ADD: '0123456789+- ',\n",
    "    MULTIPLY: '0123456789* '\n",
    "}.get(GEN_TYPE, '0123456789+-* ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 80000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "operator = {\n",
    "    SUB: ['-'],\n",
    "    SUB_ADD: ['-', '+'],\n",
    "    MULTIPLY: ['*']\n",
    "}\n",
    "ans_switcher = {\n",
    "    '+': lambda a, b: a + b,\n",
    "    '-': lambda a, b: a - b,\n",
    "    '*': lambda a, b: a * b\n",
    "}\n",
    "ops = operator.get(GEN_TYPE, [None])\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: random.choice(range(10 ** random.choice(range(1, DIGITS + 1))))\n",
    "    g = lambda: random.choice(ops)\n",
    "    a, b, op = f(), f(), g()\n",
    "    if op == '-':\n",
    "        a, b = sorted((a, b), reverse=True)\n",
    "    key = tuple((a, b, op))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    query = '{}{}{}'.format(a, op, b).ljust(MAXLEN)\n",
    "    ans_funct = ans_switcher.get(op, lambda a, b: float('NAN'))\n",
    "    ans = str(ans_funct(a, b)).ljust(ANS_DIGITS)\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6-3     = 3   \n",
      "921-895 = 26  \n",
      "720-691 = 29  \n",
      "65-6    = 59  \n",
      "915-584 = 331 \n",
      "87-6    = 81  \n",
      "46-2    = 44  \n",
      "622-186 = 436 \n",
      "522-5   = 517 \n",
      "67-1    = 66  \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(questions[i], '=', expected[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "- Size of training data:   64,000\n",
    "- Size of validation data: 16,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable:\n",
    "    def __init__(self, chars):\n",
    "        self.chars  = list(chars)\n",
    "        self.len    = len(chars)\n",
    "        self.encode = {}\n",
    "        for i, key in enumerate(self.chars):\n",
    "            self.encode[key] = np.zeros(self.len, np.float32)\n",
    "            self.encode[key][i] = 1.\n",
    "            \n",
    "    def encoder(self, C):\n",
    "        result = np.zeros((len(C), self.len))\n",
    "        for i, c in enumerate(C):\n",
    "            try:\n",
    "                result[i] = self.encode[c]\n",
    "            except:\n",
    "                pass\n",
    "        return result\n",
    "            \n",
    "    def decoder(self, x):\n",
    "        x = x.argmax(axis=-1)\n",
    "        return ''.join(self.chars[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CharacterTable(chars)\n",
    "\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), np.float32)\n",
    "y = np.zeros((len(expected), ANS_DIGITS, len(chars)), np.float32)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ct.encoder(sentence)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ct.encoder(sentence)\n",
    "\n",
    "train_x = x[:18000]\n",
    "train_y = y[:18000]\n",
    "\n",
    "validation_x = x[18000:20000]\n",
    "validation_y = y[18000:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "![model](img/seq2seq.png)\n",
    "\n",
    "- Using sequence to sequence model\n",
    "- Encoder: bi-directional LSTM\n",
    "- Decoder: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddnn_user02/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 7, 12)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 512), (None, 550912      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 512)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 512), (None, 2099200     reshape_1[0][0]                  \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[2][1]                     \n",
      "                                                                 lstm_2[2][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 12)           6156        lstm_2[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 12)           6156        lstm_2[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 12)           6156        lstm_2[3][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 4, 12)        0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4, 12)        0           reshape_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,674,736\n",
      "Trainable params: 2,674,736\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "18000/18000 [==============================] - 13s 697us/step - loss: 1.5752 - acc: 0.4310 - val_loss: 1.3468 - val_acc: 0.5026\n",
      "Epoch 2/100\n",
      "18000/18000 [==============================] - 9s 483us/step - loss: 1.1774 - acc: 0.5576 - val_loss: 1.1341 - val_acc: 0.5754\n",
      "Epoch 3/100\n",
      "18000/18000 [==============================] - 9s 492us/step - loss: 0.9774 - acc: 0.6343 - val_loss: 0.9620 - val_acc: 0.6431\n",
      "Epoch 4/100\n",
      "18000/18000 [==============================] - 9s 499us/step - loss: 0.8275 - acc: 0.6904 - val_loss: 0.8308 - val_acc: 0.6951\n",
      "Epoch 5/100\n",
      "18000/18000 [==============================] - 9s 485us/step - loss: 0.6607 - acc: 0.7589 - val_loss: 0.6749 - val_acc: 0.7398\n",
      "Epoch 6/100\n",
      "18000/18000 [==============================] - 9s 486us/step - loss: 0.4885 - acc: 0.8275 - val_loss: 0.5782 - val_acc: 0.7644\n",
      "Epoch 7/100\n",
      "18000/18000 [==============================] - 9s 494us/step - loss: 0.3649 - acc: 0.8755 - val_loss: 0.3805 - val_acc: 0.8619\n",
      "Epoch 8/100\n",
      "18000/18000 [==============================] - 9s 500us/step - loss: 0.2670 - acc: 0.9084 - val_loss: 0.2769 - val_acc: 0.8979\n",
      "Epoch 9/100\n",
      "18000/18000 [==============================] - 9s 492us/step - loss: 0.1963 - acc: 0.9328 - val_loss: 0.1779 - val_acc: 0.9380\n",
      "Epoch 10/100\n",
      "18000/18000 [==============================] - 9s 481us/step - loss: 0.1262 - acc: 0.9606 - val_loss: 0.1355 - val_acc: 0.9542\n",
      "Epoch 11/100\n",
      "18000/18000 [==============================] - 9s 496us/step - loss: 0.1266 - acc: 0.9594 - val_loss: 0.0746 - val_acc: 0.9821\n",
      "Epoch 12/100\n",
      "18000/18000 [==============================] - 9s 484us/step - loss: 0.0435 - acc: 0.9920 - val_loss: 0.0650 - val_acc: 0.9829\n",
      "Epoch 13/100\n",
      "18000/18000 [==============================] - 9s 498us/step - loss: 0.0506 - acc: 0.9865 - val_loss: 0.0598 - val_acc: 0.9801\n",
      "Epoch 14/100\n",
      "18000/18000 [==============================] - 9s 499us/step - loss: 0.0638 - acc: 0.9813 - val_loss: 0.0604 - val_acc: 0.9826\n",
      "Epoch 15/100\n",
      "18000/18000 [==============================] - 9s 495us/step - loss: 0.0386 - acc: 0.9899 - val_loss: 0.0329 - val_acc: 0.9929\n",
      "Epoch 16/100\n",
      "18000/18000 [==============================] - 9s 482us/step - loss: 0.0125 - acc: 0.9988 - val_loss: 0.0185 - val_acc: 0.9965\n",
      "Epoch 17/100\n",
      "18000/18000 [==============================] - 9s 494us/step - loss: 0.0750 - acc: 0.9763 - val_loss: 0.2214 - val_acc: 0.9201\n",
      "Epoch 18/100\n",
      "18000/18000 [==============================] - 9s 497us/step - loss: 0.0448 - acc: 0.9873 - val_loss: 0.0205 - val_acc: 0.9958\n",
      "Epoch 19/100\n",
      "18000/18000 [==============================] - 9s 494us/step - loss: 0.0075 - acc: 0.9997 - val_loss: 0.0136 - val_acc: 0.9973\n",
      "Epoch 20/100\n",
      " 6600/18000 [==========>...................] - ETA: 5s - loss: 0.0058 - acc: 0.9997"
     ]
    }
   ],
   "source": [
    "import keras as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Lambda\n",
    "from keras.layers import Input, LSTM, TimeDistributed, Dropout, RepeatVector, Reshape, Bidirectional, Concatenate, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "EMBEDDING_SIZE = 256\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "encoder_inputs = Input(shape=(MAXLEN, len(chars)))\n",
    "# encoder_inputs = Input(shape=(MAXLEN,))\n",
    "# embedding = Embedding(len(chars), EMBEDDING_SIZE)(encoder_inputs)\n",
    "encoder = Bidirectional(LSTM(HIDDEN_SIZE, return_state=True))\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "states = [state_h, state_c]\n",
    "\n",
    "# decoder_inputs = RepeatVector(ANS_DIGITS)(encoder_outputs)\n",
    "# decoder_outputs = Bidirectional(LSTM(int(HIDDEN_SIZE / 2), return_sequences=True))(decoder_inputs)\n",
    "# decoder_outputs = TimeDistributed(Dense(len(chars), activation='softmax'))(decoder_outputs)\n",
    "\n",
    "# Set up the decoder, which will only process one timestep at a time.\n",
    "decoder_inputs = Reshape((1, HIDDEN_SIZE * 2))\n",
    "decoder_lstm = LSTM(HIDDEN_SIZE * 2, return_state=True)\n",
    "\n",
    "all_outputs = []\n",
    "inputs = decoder_inputs(encoder_outputs)\n",
    "\n",
    "first_decoder = True\n",
    "for _ in range(ANS_DIGITS):\n",
    "    # Run the decoder on one timestep\n",
    "    outputs, state_h, state_c = decoder_lstm(inputs,\n",
    "                                             initial_state=states)\n",
    "    \n",
    "    # Reinject the outputs as inputs for the next loop iteration\n",
    "    # as well as update the states\n",
    "    states = [state_h, state_c]\n",
    "#     inputs = decoder_inputs(outputs)\n",
    "    \n",
    "    # Store the current prediction (we will concatenate all predictions later)\n",
    "    outputs = Dense(len(chars), activation='softmax')(outputs)\n",
    "    all_outputs.append(outputs)\n",
    "    \n",
    "\n",
    "# Concatenate all predictions\n",
    "decoder_outputs = Concatenate()(all_outputs)\n",
    "decoder_outputs = Reshape((ANS_DIGITS, len(chars)))(decoder_outputs)\n",
    "decoder_outputs = Lambda(lambda x: x[:,::-1])(decoder_outputs)\n",
    "\n",
    "# Define and compile model as previously\n",
    "model = Model(encoder_inputs, decoder_outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = int(len(train_x) / 128 / 100) * 100\n",
    "\n",
    "if batch_size == 0:\n",
    "    batch_size = 100\n",
    "\n",
    "    \n",
    "model.fit(train_x, train_y, \n",
    "          batch_size=batch_size, epochs=100, \n",
    "          verbose=1, validation_data=[validation_x, validation_y])\n",
    "\n",
    "# model.fit(np.argmax(train_x, axis=2), train_y, \n",
    "#           batch_size=batch_size, epochs=100, \n",
    "#           verbose=1, validation_data=[np.argmax(validation_x, axis=2), validation_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Error check')\n",
    "pred = model.predict(x)\n",
    "err = []\n",
    "for i in range(len(x)):\n",
    "    if ct.decoder(pred[i]) != ct.decoder(y[i]):\n",
    "        err.append(i)\n",
    "print(len(err), '/', len(x))\n",
    "print()\n",
    "print('Prediction'.ljust(MAXLEN + ANS_DIGITS + 3),'Ans')\n",
    "print('-' * (MAXLEN + ANS_DIGITS * 2 + 4))\n",
    "for i in err:\n",
    "    print(ct.decoder(x[i]), '=', ct.decoder(pred[i]), ct.decoder(y[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '100-5'\n",
    "\n",
    "q_padding = q.ljust(MAXLEN)[:MAXLEN]\n",
    "test_x = ct.encoder(q_padding)\n",
    "pred_y = model.predict(test_x.reshape(-1, MAXLEN, len(chars)))\n",
    "print(q, '=', ct.decoder(pred_y[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
