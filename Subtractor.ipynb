{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUB      = 0\n",
    "SUB_ADD  = 1\n",
    "MULTIPLY = 2\n",
    "\n",
    "GEN_TYPE = SUB\n",
    "\n",
    "TRAINING_SIZE = 80000\n",
    "DIGITS = 3\n",
    "ANS_DIGITS = {\n",
    "    SUB: DIGITS + 1,\n",
    "    SUB_ADD: DIGITS + 1,\n",
    "    MULTIPLY: 2 * DIGITS\n",
    "}.get(GEN_TYPE, DIGITS + 1)\n",
    "MAXLEN = DIGITS + 1 + DIGITS\n",
    "chars = {\n",
    "    SUB: '0123456789- ',\n",
    "    SUB_ADD: '0123456789+- ',\n",
    "    MULTIPLY: '0123456789* '\n",
    "}.get(GEN_TYPE, '0123456789+-* ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 80000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "operator = {\n",
    "    SUB: ['-'],\n",
    "    SUB_ADD: ['-', '+'],\n",
    "    MULTIPLY: ['*']\n",
    "}\n",
    "ans_switcher = {\n",
    "    '+': lambda a, b: a + b,\n",
    "    '-': lambda a, b: a - b,\n",
    "    '*': lambda a, b: a * b\n",
    "}\n",
    "ops = operator.get(GEN_TYPE, [None])\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: random.choice(range(10 ** random.choice(range(1, DIGITS + 1))))\n",
    "    g = lambda: random.choice(ops)\n",
    "    a, b, op = f(), f(), g()\n",
    "    if op == '-':\n",
    "        a, b = sorted((a, b), reverse=True)\n",
    "    key = tuple((a, b, op))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    query = '{}{}{}'.format(a, op, b).ljust(MAXLEN)\n",
    "    ans_funct = ans_switcher.get(op, lambda a, b: float('NAN'))\n",
    "    ans = str(ans_funct(a, b)).ljust(ANS_DIGITS)\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875-9   = 866 \n",
      "93-9    = 84  \n",
      "77-5    = 72  \n",
      "82-79   = 3   \n",
      "876-249 = 627 \n",
      "67-1    = 66  \n",
      "84-75   = 9   \n",
      "400-2   = 398 \n",
      "559-337 = 222 \n",
      "346-8   = 338 \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(questions[i], '=', expected[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "- Size of training data:   64,000\n",
    "- Size of validation data: 16,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterTable:\n",
    "    def __init__(self, chars):\n",
    "        self.chars  = list(chars)\n",
    "        self.len    = len(chars)\n",
    "        self.encode = {}\n",
    "        for i, key in enumerate(self.chars):\n",
    "            self.encode[key] = np.zeros(self.len, np.float32)\n",
    "            self.encode[key][i] = 1.\n",
    "            \n",
    "    def encoder(self, C):\n",
    "        result = np.zeros((len(C), self.len))\n",
    "        for i, c in enumerate(C):\n",
    "            try:\n",
    "                result[i] = self.encode[c]\n",
    "            except:\n",
    "                pass\n",
    "        return result\n",
    "            \n",
    "    def decoder(self, x):\n",
    "        x = x.argmax(axis=-1)\n",
    "        return ''.join(self.chars[i] for i in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CharacterTable(chars)\n",
    "\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), np.float32)\n",
    "y = np.zeros((len(expected), ANS_DIGITS, len(chars)), np.float32)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ct.encoder(sentence)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ct.encoder(sentence)\n",
    "\n",
    "train_x = x[:18000]\n",
    "train_y = y[:18000]\n",
    "\n",
    "validation_x = x[18000:20000]\n",
    "validation_y = y[18000:20000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "![model](img/seq2seq.png)\n",
    "\n",
    "- Using sequence to sequence model\n",
    "- Encoder: bi-directional LSTM\n",
    "- Decoder: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddnn_user02/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 7, 12)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 512), (None, 550912      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 1, 512)       0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 512)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 512), (None, 2099200     reshape_1[0][0]                  \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[1][1]                     \n",
      "                                                                 lstm_2[1][2]                     \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 lstm_2[2][1]                     \n",
      "                                                                 lstm_2[2][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 12)           6156        lstm_2[1][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 12)           6156        lstm_2[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 12)           6156        lstm_2[3][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 4, 12)        0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4, 12)        0           reshape_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,674,736\n",
      "Trainable params: 2,674,736\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "18000/18000 [==============================] - 13s 708us/step - loss: 1.5779 - acc: 0.4334 - val_loss: 1.3474 - val_acc: 0.4995\n",
      "Epoch 2/100\n",
      "18000/18000 [==============================] - 9s 500us/step - loss: 1.1473 - acc: 0.5709 - val_loss: 1.0996 - val_acc: 0.5866\n",
      "Epoch 3/100\n",
      "18000/18000 [==============================] - 9s 490us/step - loss: 0.9264 - acc: 0.6540 - val_loss: 0.9342 - val_acc: 0.6417\n",
      "Epoch 4/100\n",
      "18000/18000 [==============================] - 9s 506us/step - loss: 0.7514 - acc: 0.7198 - val_loss: 0.7494 - val_acc: 0.7190\n",
      "Epoch 5/100\n",
      "18000/18000 [==============================] - 9s 500us/step - loss: 0.5254 - acc: 0.8128 - val_loss: 0.5091 - val_acc: 0.8133\n",
      "Epoch 6/100\n",
      "18000/18000 [==============================] - 9s 514us/step - loss: 0.3355 - acc: 0.8843 - val_loss: 0.2804 - val_acc: 0.9110\n",
      "Epoch 7/100\n",
      "18000/18000 [==============================] - 9s 488us/step - loss: 0.2072 - acc: 0.9330 - val_loss: 0.3079 - val_acc: 0.8894\n",
      "Epoch 8/100\n",
      "18000/18000 [==============================] - 9s 496us/step - loss: 0.1361 - acc: 0.9579 - val_loss: 0.1495 - val_acc: 0.9517\n",
      "Epoch 9/100\n",
      "18000/18000 [==============================] - 9s 486us/step - loss: 0.1052 - acc: 0.9677 - val_loss: 0.0801 - val_acc: 0.9784\n",
      "Epoch 10/100\n",
      "18000/18000 [==============================] - 9s 499us/step - loss: 0.0703 - acc: 0.9799 - val_loss: 0.1046 - val_acc: 0.9658\n",
      "Epoch 11/100\n",
      "18000/18000 [==============================] - 9s 487us/step - loss: 0.0746 - acc: 0.9781 - val_loss: 0.0360 - val_acc: 0.9938\n",
      "Epoch 12/100\n",
      "18000/18000 [==============================] - 9s 490us/step - loss: 0.0253 - acc: 0.9958 - val_loss: 0.0416 - val_acc: 0.9906\n",
      "Epoch 13/100\n",
      "18000/18000 [==============================] - 9s 498us/step - loss: 0.0635 - acc: 0.9798 - val_loss: 0.0862 - val_acc: 0.9716\n",
      "Epoch 14/100\n",
      "18000/18000 [==============================] - 9s 493us/step - loss: 0.0239 - acc: 0.9953 - val_loss: 0.0496 - val_acc: 0.9833\n",
      "Epoch 15/100\n",
      "18000/18000 [==============================] - 9s 493us/step - loss: 0.0396 - acc: 0.9884 - val_loss: 0.0330 - val_acc: 0.9905\n",
      "Epoch 16/100\n",
      "18000/18000 [==============================] - 9s 506us/step - loss: 0.0353 - acc: 0.9901 - val_loss: 0.0244 - val_acc: 0.9945\n",
      "Epoch 17/100\n",
      "18000/18000 [==============================] - 9s 483us/step - loss: 0.0077 - acc: 0.9993 - val_loss: 0.0106 - val_acc: 0.9986\n",
      "Epoch 18/100\n",
      "18000/18000 [==============================] - 9s 490us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.0076 - val_acc: 0.9991\n",
      "Epoch 19/100\n",
      "18000/18000 [==============================] - 9s 495us/step - loss: 0.0030 - acc: 0.9999 - val_loss: 0.0064 - val_acc: 0.9993\n",
      "Epoch 20/100\n",
      "18000/18000 [==============================] - 9s 504us/step - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0055 - val_acc: 0.9994\n",
      "Epoch 21/100\n",
      "18000/18000 [==============================] - 9s 488us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9995\n",
      "Epoch 22/100\n",
      "18000/18000 [==============================] - 9s 501us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9991\n",
      "Epoch 23/100\n",
      "18000/18000 [==============================] - 9s 492us/step - loss: 0.1170 - acc: 0.9644 - val_loss: 0.1188 - val_acc: 0.9561\n",
      "Epoch 24/100\n",
      "18000/18000 [==============================] - 9s 498us/step - loss: 0.0207 - acc: 0.9956 - val_loss: 0.0112 - val_acc: 0.9984\n",
      "Epoch 25/100\n",
      "18000/18000 [==============================] - 9s 488us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9993\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 9s 501us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9990\n",
      "Epoch 27/100\n",
      "18000/18000 [==============================] - 9s 498us/step - loss: 0.0812 - acc: 0.9732 - val_loss: 0.0872 - val_acc: 0.9708\n",
      "Epoch 28/100\n",
      "18000/18000 [==============================] - 9s 512us/step - loss: 0.0305 - acc: 0.9913 - val_loss: 0.0314 - val_acc: 0.9896\n",
      "Epoch 29/100\n",
      "18000/18000 [==============================] - 9s 507us/step - loss: 0.0164 - acc: 0.9955 - val_loss: 0.0221 - val_acc: 0.9938\n",
      "Epoch 30/100\n",
      "18000/18000 [==============================] - 9s 497us/step - loss: 0.0213 - acc: 0.9934 - val_loss: 0.0150 - val_acc: 0.9959\n",
      "Epoch 31/100\n",
      "18000/18000 [==============================] - 9s 507us/step - loss: 0.0144 - acc: 0.9957 - val_loss: 0.0737 - val_acc: 0.9743\n",
      "Epoch 32/100\n",
      "18000/18000 [==============================] - 9s 497us/step - loss: 0.0482 - acc: 0.9848 - val_loss: 0.0125 - val_acc: 0.9971\n",
      "Epoch 33/100\n",
      "18000/18000 [==============================] - 9s 505us/step - loss: 0.0022 - acc: 0.9999 - val_loss: 0.0050 - val_acc: 0.9989\n",
      "Epoch 34/100\n",
      "18000/18000 [==============================] - 9s 498us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9991\n",
      "Epoch 35/100\n",
      "18000/18000 [==============================] - 9s 506us/step - loss: 9.2324e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9990\n",
      "Epoch 36/100\n",
      "18000/18000 [==============================] - 9s 512us/step - loss: 7.6770e-04 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9991\n",
      "Epoch 37/100\n",
      "18000/18000 [==============================] - 9s 503us/step - loss: 6.5367e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9995\n",
      "Epoch 38/100\n",
      "18000/18000 [==============================] - 9s 504us/step - loss: 5.6631e-04 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9993\n",
      "Epoch 39/100\n",
      "18000/18000 [==============================] - 9s 506us/step - loss: 4.9543e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9993\n",
      "Epoch 40/100\n",
      "18000/18000 [==============================] - 9s 502us/step - loss: 4.3605e-04 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9993\n",
      "Epoch 41/100\n",
      "18000/18000 [==============================] - 9s 487us/step - loss: 3.8719e-04 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9994\n",
      "Epoch 42/100\n",
      "18000/18000 [==============================] - 9s 492us/step - loss: 3.4528e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9994\n",
      "Epoch 43/100\n",
      "18000/18000 [==============================] - 9s 485us/step - loss: 3.0902e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9995\n",
      "Epoch 44/100\n",
      "18000/18000 [==============================] - 9s 498us/step - loss: 2.7678e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9994\n",
      "Epoch 45/100\n",
      "18000/18000 [==============================] - 9s 503us/step - loss: 2.4942e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9995\n",
      "Epoch 46/100\n",
      "18000/18000 [==============================] - 9s 503us/step - loss: 2.2484e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9996\n",
      "Epoch 47/100\n",
      "18000/18000 [==============================] - 9s 509us/step - loss: 2.0266e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9994\n",
      "Epoch 48/100\n",
      "18000/18000 [==============================] - 9s 497us/step - loss: 1.8312e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9995\n",
      "Epoch 49/100\n",
      "18000/18000 [==============================] - 9s 515us/step - loss: 1.6563e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9996\n",
      "Epoch 50/100\n",
      "18000/18000 [==============================] - 9s 491us/step - loss: 1.4989e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9996\n",
      "Epoch 51/100\n",
      "18000/18000 [==============================] - 9s 487us/step - loss: 1.3599e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9996\n",
      "Epoch 52/100\n",
      "18000/18000 [==============================] - 9s 486us/step - loss: 1.2322e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9996\n",
      "Epoch 53/100\n",
      "18000/18000 [==============================] - 9s 499us/step - loss: 1.1192e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9996\n",
      "Epoch 54/100\n",
      "18000/18000 [==============================] - 9s 510us/step - loss: 1.0148e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9996\n",
      "Epoch 55/100\n",
      "18000/18000 [==============================] - 9s 499us/step - loss: 9.2193e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9998\n",
      "Epoch 56/100\n",
      "18000/18000 [==============================] - 9s 486us/step - loss: 8.3775e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9998\n",
      "Epoch 57/100\n",
      "18000/18000 [==============================] - 9s 494us/step - loss: 7.6051e-05 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9998\n",
      "Epoch 58/100\n",
      "18000/18000 [==============================] - 9s 503us/step - loss: 6.9062e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9998\n",
      "Epoch 59/100\n",
      "18000/18000 [==============================] - 9s 495us/step - loss: 6.2813e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9998\n",
      "Epoch 60/100\n",
      "18000/18000 [==============================] - 9s 486us/step - loss: 5.6924e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9998\n",
      "Epoch 61/100\n",
      "18000/18000 [==============================] - 9s 494us/step - loss: 5.1791e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 62/100\n",
      "18000/18000 [==============================] - 9s 486us/step - loss: 4.7034e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9998\n",
      "Epoch 63/100\n",
      "18000/18000 [==============================] - 9s 503us/step - loss: 4.2712e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 64/100\n",
      "18000/18000 [==============================] - 9s 503us/step - loss: 3.8823e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 65/100\n",
      "18000/18000 [==============================] - 9s 486us/step - loss: 3.5301e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 66/100\n",
      "18000/18000 [==============================] - 9s 513us/step - loss: 3.2078e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 67/100\n",
      "18000/18000 [==============================] - 9s 509us/step - loss: 2.9147e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 68/100\n",
      "18000/18000 [==============================] - 8s 470us/step - loss: 2.6497e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 69/100\n",
      "18000/18000 [==============================] - 9s 493us/step - loss: 2.4098e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 70/100\n",
      "18000/18000 [==============================] - 9s 495us/step - loss: 2.1906e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 71/100\n",
      "18000/18000 [==============================] - 9s 493us/step - loss: 1.9943e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 72/100\n",
      "18000/18000 [==============================] - 9s 503us/step - loss: 1.8126e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 73/100\n",
      "18000/18000 [==============================] - 9s 515us/step - loss: 1.6511e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 74/100\n",
      "18000/18000 [==============================] - 9s 497us/step - loss: 1.4988e-05 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 75/100\n",
      "18000/18000 [==============================] - 9s 509us/step - loss: 1.3621e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 76/100\n",
      "18000/18000 [==============================] - 9s 501us/step - loss: 1.2420e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 77/100\n",
      "18000/18000 [==============================] - 9s 489us/step - loss: 1.1294e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 78/100\n",
      "18000/18000 [==============================] - 9s 489us/step - loss: 1.0282e-05 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 79/100\n",
      "18000/18000 [==============================] - 9s 505us/step - loss: 9.3683e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 80/100\n",
      "18000/18000 [==============================] - 9s 496us/step - loss: 8.5357e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 81/100\n",
      "18000/18000 [==============================] - 9s 502us/step - loss: 7.7743e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 82/100\n",
      "18000/18000 [==============================] - 9s 500us/step - loss: 7.0796e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 9s 495us/step - loss: 6.4462e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 84/100\n",
      "18000/18000 [==============================] - 9s 501us/step - loss: 5.8839e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 85/100\n",
      "18000/18000 [==============================] - 9s 497us/step - loss: 5.3657e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 86/100\n",
      "18000/18000 [==============================] - 9s 482us/step - loss: 4.8978e-06 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9999\n",
      "Epoch 87/100\n",
      "18000/18000 [==============================] - 9s 508us/step - loss: 4.4676e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 88/100\n",
      "18000/18000 [==============================] - 9s 490us/step - loss: 4.0811e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 89/100\n",
      "18000/18000 [==============================] - 9s 483us/step - loss: 3.7238e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 90/100\n",
      "18000/18000 [==============================] - 9s 485us/step - loss: 3.4044e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 91/100\n",
      "18000/18000 [==============================] - 9s 488us/step - loss: 3.1139e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 92/100\n",
      "18000/18000 [==============================] - 9s 500us/step - loss: 2.8434e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 93/100\n",
      "18000/18000 [==============================] - 9s 489us/step - loss: 2.6021e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 94/100\n",
      "18000/18000 [==============================] - 9s 488us/step - loss: 2.3858e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 95/100\n",
      "18000/18000 [==============================] - 9s 485us/step - loss: 2.1808e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 96/100\n",
      "18000/18000 [==============================] - 9s 483us/step - loss: 1.9987e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9999\n",
      "Epoch 97/100\n",
      "18000/18000 [==============================] - 9s 501us/step - loss: 1.8362e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 98/100\n",
      "18000/18000 [==============================] - 9s 495us/step - loss: 1.6818e-06 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9999\n",
      "Epoch 99/100\n",
      "18000/18000 [==============================] - 9s 487us/step - loss: 1.5449e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9999\n",
      "Epoch 100/100\n",
      "18000/18000 [==============================] - 9s 476us/step - loss: 1.4196e-06 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f13bc2de668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation, Lambda\n",
    "from keras.layers import Input, LSTM, TimeDistributed, Dropout, RepeatVector, Reshape, Bidirectional, Concatenate, Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model\n",
    "\n",
    "HIDDEN_SIZE = 256\n",
    "EMBEDDING_SIZE = 256\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "encoder_inputs = Input(shape=(MAXLEN, len(chars)))\n",
    "# encoder_inputs = Input(shape=(MAXLEN,))\n",
    "# embedding = Embedding(len(chars), EMBEDDING_SIZE)(encoder_inputs)\n",
    "encoder = Bidirectional(LSTM(HIDDEN_SIZE, return_state=True))\n",
    "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder(encoder_inputs)\n",
    "\n",
    "state_h = Concatenate()([forward_h, backward_h])\n",
    "state_c = Concatenate()([forward_c, backward_c])\n",
    "states = [state_h, state_c]\n",
    "\n",
    "# decoder_inputs = RepeatVector(ANS_DIGITS)(encoder_outputs)\n",
    "# decoder_outputs = Bidirectional(LSTM(int(HIDDEN_SIZE / 2), return_sequences=True))(decoder_inputs)\n",
    "# decoder_outputs = TimeDistributed(Dense(len(chars), activation='softmax'))(decoder_outputs)\n",
    "\n",
    "# Set up the decoder, which will only process one timestep at a time.\n",
    "decoder_inputs = Reshape((1, HIDDEN_SIZE * 2))\n",
    "decoder_lstm = LSTM(HIDDEN_SIZE * 2, return_state=True)\n",
    "\n",
    "all_outputs = []\n",
    "inputs = decoder_inputs(encoder_outputs)\n",
    "\n",
    "first_decoder = True\n",
    "for _ in range(ANS_DIGITS):\n",
    "    # Run the decoder on one timestep\n",
    "    outputs, state_h, state_c = decoder_lstm(inputs,\n",
    "                                             initial_state=states)\n",
    "    \n",
    "    # Reinject the outputs as inputs for the next loop iteration\n",
    "    # as well as update the states\n",
    "    states = [state_h, state_c]\n",
    "#     inputs = decoder_inputs(outputs)\n",
    "    \n",
    "    # Store the current prediction (we will concatenate all predictions later)\n",
    "    outputs = Dense(len(chars), activation='softmax')(outputs)\n",
    "    all_outputs.append(outputs)\n",
    "    \n",
    "\n",
    "# Concatenate all predictions\n",
    "decoder_outputs = Concatenate()(all_outputs)\n",
    "decoder_outputs = Reshape((ANS_DIGITS, len(chars)))(decoder_outputs)\n",
    "decoder_outputs = Lambda(lambda x: x[:,::-1])(decoder_outputs)\n",
    "\n",
    "# Define and compile model as previously\n",
    "model = Model(encoder_inputs, decoder_outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size = int(len(train_x) / 128 / 100) * 100\n",
    "\n",
    "if batch_size == 0:\n",
    "    batch_size = 100\n",
    "\n",
    "    \n",
    "model.fit(train_x, train_y, \n",
    "          batch_size=batch_size, epochs=100, \n",
    "          verbose=1, validation_data=[validation_x, validation_y])\n",
    "\n",
    "# model.fit(np.argmax(train_x, axis=2), train_y, \n",
    "#           batch_size=batch_size, epochs=100, \n",
    "#           verbose=1, validation_data=[np.argmax(validation_x, axis=2), validation_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error check\n",
      "103 / 80000\n",
      "\n",
      "Prediction     Ans\n",
      "-------------------\n",
      "100-98  = 1    2   \n",
      "290-269 = 22   21  \n",
      "280-259 = 22   21  \n",
      "191-189 = 1    2   \n",
      "207-199 = 7    8   \n",
      "398-330 = 69   68  \n",
      "930-888 = 43   42  \n",
      "660-609 = 52   51  \n",
      "204-196 = 7    8   \n",
      "699-510 = 199  189 \n",
      "895-808 = 77   87  \n",
      "869-860 = 8    9   \n",
      "507-499 = 7    8   \n",
      "690-529 = 151  161 \n",
      "100-97  = 1    3   \n",
      "103-97  = 1    6   \n",
      "199-138 = 71   61  \n",
      "500-496 = 3    4   \n",
      "100-92  = 9    8   \n",
      "100-39  = 71   61  \n",
      "104-98  = 1    6   \n",
      "592-502 = 80   90  \n",
      "901-893 = 7    8   \n",
      "720-688 = 22   32  \n",
      "900-818 = 92   82  \n",
      "260-259 = 2    1   \n",
      "900-895 = 6    5   \n",
      "102-94  = 9    8   \n",
      "721-679 = 43   42  \n",
      "900-298 = 601  602 \n",
      "104-99  = 1    5   \n",
      "102-98  = 1    4   \n",
      "990-948 = 43   42  \n",
      "930-878 = 53   52  \n",
      "491-428 = 64   63  \n",
      "800-695 = 10   105 \n",
      "902-888 = 1    14  \n",
      "290-227 = 64   63  \n",
      "596-488 = 1    108 \n",
      "689-500 = 199  189 \n",
      "670-639 = 32   31  \n",
      "960-298 = 661  662 \n",
      "101-97  = 14   4   \n",
      "104-96  = 9    8   \n",
      "794-789 = 4    5   \n",
      "172-109 = 62   63  \n",
      "870-789 = 82   81  \n",
      "926-819 = 10   107 \n",
      "101-95  = 1    6   \n",
      "917-910 = 8    7   \n",
      "102-99  = 1    3   \n",
      "101-98  = 1    3   \n",
      "504-496 = 7    8   \n",
      "290-289 = 2    1   \n",
      "361-308 = 54   53  \n",
      "297-200 = 96   97  \n",
      "941-909 = 31   32  \n",
      "981-199 = 781  782 \n",
      "101-93  = 9    8   \n",
      "810-709 = 102  101 \n",
      "389-380 = 8    9   \n",
      "791-409 = 381  382 \n",
      "820-695 = 115  125 \n",
      "101-99  = 1    2   \n",
      "219-122 = 98   97  \n",
      "220-219 = 2    1   \n",
      "491-409 = 81   82  \n",
      "929-830 = 999  99  \n",
      "234-142 = 922  92  \n",
      "971-299 = 671  672 \n",
      "918-900 = 19   18  \n",
      "730-718 = 13   12  \n",
      "462-409 = 54   53  \n",
      "954-855 = 999  99  \n",
      "250-249 = 2    1   \n",
      "929-920 = 8    9   \n",
      "210-107 = 10   103 \n",
      "681-608 = 74   73  \n",
      "920-794 = 116  126 \n",
      "118-101 = 1    17  \n",
      "680-639 = 42   41  \n",
      "991-299 = 691  692 \n",
      "780-729 = 52   51  \n",
      "921-889 = 22   32  \n",
      "660-629 = 32   31  \n",
      "209-200 = 1    9   \n",
      "280-279 = 2    1   \n",
      "880-807 = 74   73  \n",
      "492-402 = 80   90  \n",
      "759-750 = 8    9   \n",
      "690-627 = 64   63  \n",
      "599-517 = 92   82  \n",
      "192-102 = 80   90  \n",
      "799-701 = 99   98  \n",
      "303-298 = 6    5   \n",
      "491-418 = 74   73  \n",
      "802-794 = 7    8   \n",
      "600-579 = 11   21  \n",
      "404-400 = 1    4   \n",
      "290-249 = 42   41  \n",
      "990-907 = 84   83  \n",
      "980-979 = 91   1   \n",
      "740-679 = 62   61  \n"
     ]
    }
   ],
   "source": [
    "print('Error check')\n",
    "pred = model.predict(x)\n",
    "err = []\n",
    "for i in range(len(x)):\n",
    "    if ct.decoder(pred[i]) != ct.decoder(y[i]):\n",
    "        err.append(i)\n",
    "print(len(err), '/', len(x))\n",
    "print()\n",
    "print('Prediction'.ljust(MAXLEN + ANS_DIGITS + 3),'Ans')\n",
    "print('-' * (MAXLEN + ANS_DIGITS * 2 + 4))\n",
    "for i in err:\n",
    "    print(ct.decoder(x[i]), '=', ct.decoder(pred[i]), ct.decoder(y[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100-5 = 95  \n"
     ]
    }
   ],
   "source": [
    "q = '100-5'\n",
    "\n",
    "q_padding = q.ljust(MAXLEN)[:MAXLEN]\n",
    "test_x = ct.encoder(q_padding)\n",
    "pred_y = model.predict(test_x.reshape(-1, MAXLEN, len(chars)))\n",
    "print(q, '=', ct.decoder(pred_y[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
